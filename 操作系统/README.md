# 操作系统


> * [并行和并发](#并行和并发)
> * [计算密集任务和IO密集任务](#计算密集任务和IO密集任务)
> * [单核CPU/多核CPU/多CPU](#单核CPU多核CPU多CPU)
> * [什么时候使用多线程和多进程](#什么时候使用多线程和多进程)
> * [进程与PCB](#进程与PCB)
> * [进程间通信](#进程间通信)
> * [进程调度算法](#进程调度算法)
> * [僵尸进程和孤儿进程](#僵尸进程和孤儿进程)
> * [进程状态转移](#进程状态转移)
> * [进程间共享和私有资源](#进程间共享和私有资源)
> * [线程](#线程)
> * [协程](#协程)
> * [线程间同步及系统调用](#线程间同步及系统调用)
> * [线程间共享和私有资源](#线程间共享和私有资源)
> * [进程与线程的区别](#进程与线程的区别)
> * [用户态和内核态](#用户态和内核态)
> * [什么是虚拟内存](#什么是虚拟内存)
> * [缺页中断](#缺页中断)
> * [虚拟内存置换算法](#虚拟内存置换算法)
> * [虚拟内存页表寻址](#虚拟内存页表寻址)
> * [说一下LINUX系统中的锁](#说一下LINUX系统中的锁)
> * [自旋锁发生死锁](#自旋锁发生死锁)
> * [死锁产生的条件](#死锁产生的条件)
> * [如何避免死锁](#如何避免死锁)
> * [死锁检测和死锁恢复](#死锁检测和死锁恢复)

## 并行和并发
* 并发
    * 在同一时刻只能有一条指令执行，但多个进程指令被快速轮换执行，使得在宏观上具有多个进程同时执行的效果。

* 并行
    * 在同一时刻，有多条指令在多个处理器上同时执行。

## 计算密集任务和IO密集任务
* 计算密集型任务
    * 特点是要进行大量的计算，消耗CPU资源，比如计算圆周率、对视频进行高清解码等等，全靠CPU的运算能力。
    * 虽然可以用多任务完成，但是任务越多，花在任务切换的时间就越多，CPU执行任务的效率就越低，所以，要最高效地利用CPU，计算密集型任务同时进行的数量应当等于CPU的核心数。

* IO密集型任务
    * 涉及到网络、磁盘IO的任务都是IO密集型任务，这类任务的特点是CPU消耗很少，任务的大部分时间都在等待IO操作完成（因为IO的速度远远低于CPU和内存的速度）。
    * 对于IO密集型任务，任务越多，CPU效率越高，但也有一个限度。常见的大部分任务都是IO密集型任务，比如Web应用。

## [单核CPU/多核CPU/多CPU](https://www.cnblogs.com/csfeng/p/8670704.html)

> * 都是一个CPU，不同的是每个CPU上的核心数。
> * 多核CPU是多个CPU的替代方案，同时也减少了功耗。
> * 一个核心只能同时执行一个线程。

* 单核CPU
    * 一个CPU中只有一个核心处理器
* 多核CPU
    * 一个CPU有多个核心处理器，处理器之间通过**CPU内部总线**进行通讯
* 多CPU
    * 简单的多个CPU工作在同一个系统上，多个CPU之间通过**主板上的总线**进行通讯

### 深入理解进程和线程
* 进程的调度和资源分配是操作系统负责

* 线程的调度和资源分配是CPU负责

* 进程是操作系统资源分配(包括cpu、内存、磁盘IO等)的基本单位，一个CPU同时刻只能执行一个进程
    * **单核CPU实现多进程，并发。** 通过操作系统的进程调度算法，单核CPU进行进程调度的时候，需要读取上下文+执行程序+保存上下文，即进程切换。
    * **多CPU实现多进程，并行。** 不同的进程运行在不同的CPU上。
    
* 线程是CPU调度和资源分配的基本单位，一个CPU核心同时刻只能执行一个线程
    * **单核CPU实现多线程，并发。** 不同线程为了使用CPU核心，则会进行线程切换，但是由于共享了程序执行环境，这个线程切换比进程切换开销少了很多。
    * **多核CPU实现多线程，并行。** CPU可以将不同线程分配到不同的CPU核心处理器中。

> * 单CPU中进程只能是并发，多CPU计算机中进程可以并行。
> * 单CPU单核中线程只能并发，单CPU多核中线程可以并行。
> * 并行有上限，进程与CPU个数，线程与CPU核心个数有关，并不是所有线程和所有进程都能同时运行

## 什么时候使用多进程和多线程
* 多核CPU——计算密集型任务。此时要尽量使用多线程，可以提高任务执行效率，例如加密解密，数据压缩解压缩（视频、音频、普通数据），否则只能使一个核心满载，而其他核心闲置.
* 单核CPU——计算密集型任务。此时的任务已经把CPU资源100%消耗了，就没必要也不可能使用多线程来提高计算效率了；相反，如果要做人机交互，最好还是要用多线程，避免用户没法对计算机进行操作。
* 单核CPU——IO密集型任务，使用多线程还是为了人机交互方便.
* 多核CPU——IO密集型任务，这就更不用说了，跟单核时候原因一样。

## 进程与PCB
进程是操作系统的资源分配单位，实现操作系统的并发。
PCB(Process Control Block)进程控制块，描述进程的基本信息和运行状态，进程的创建和销毁都是对PCB进行操作，PCB的内容实际上是各种数据、代码的地址或索引表地址。

## 进程间同步
信号量

## 进程间通信
进程间通信主要包括管道、系统IPC（包括消息队列、信号、共享内存等）、本地套接字socket。

* 管道(缓冲区有限)
    * 无名管道PIPE
        *  一种半双工的通信方式，只能在具有亲缘关系的进程间使用（父子进程或兄弟进程）
    * 有名管道FIFO
        *  一种半双工的通信方式，可以在非亲缘关系的进程间使用
* 消息队列
    * 消息队列是消息的链接表，存放在内核中并由消息队列标识符标识
    * 消息队列克服了信号传递信息少，管道缓冲区大小受限的缺点
    * 一个消息队列由一个标识符（即队列ID）来标记
* 信号
    * 信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生。  
* [共享内存](https://blog.csdn.net/hj605635529/article/details/73163513)
    * 它使得多个进程可以访问同一块内存空间，不同进程可以及时看到对方进程中对共享内存中数据得更新。多个进程可以同时操作，所以需要进行同步 ，一般与信号量配合使用。    
    * shm
    * mmap
* 套接字
    * 本地套接字用于本机不同进程间通信，另外普通套接字可以用于不同主机间的进程间通信

## 进程调度算法
### 批处理系统
批处理系统没有太多的用户操作，在该系统中，调度算法目标是保证吞吐量和周转时间（从提交到终止的时间）。

* 先来先服务 first-come first-serverd（FCFS）
> * 非抢占式的调度算法，按照请求的顺序进行调度。
> * 有利于长作业，但不利于短作业，因为短作业必须一直等待前面的长作业执行完毕才能执行，而长作业又需要执行很长时间，造成了短作业等待时间过长。

* 短作业优先 shortest job first（SJF）
> * 非抢占式的调度算法，按估计运行时间最短的顺序进行调度。
> * 长作业有可能会饿死，处于一直等待短作业执行完毕的状态。因为如果一直有短作业到来，那么长作业永远得不到调度。
    
* 最短剩余时间优先 shortest remaining time next（SRTN）
> * 最短作业优先的抢占式版本，按剩余运行时间的顺序进行调度。 
> * 当一个新的作业到达时，其整个运行时间与当前进程的剩余时间作比较。如果新的进程需要的时间更少，则挂起当前进程，运行新的进程。否则新的进程等待。

### 交互式系统
交互式系统有大量的用户交互操作，在该系统中调度算法的目标是快速地进行响应。

* 时间片轮转
> * 将所有就绪进程按 FCFS 的原则排成一个队列，每次调度时，把 CPU 时间分配给队首进程，该进程可以执行一个时间片。
> * 当时间片用完时，由计时器发出时钟中断，调度程序便停止该进程的执行，并将它送往就绪队列的末尾，同时继续把 CPU 时间分配给队首的进程。

* 优先级调度
> * 为每个进程分配一个优先级，按优先级进行调度。
> * 为了防止低优先级的进程永远等不到调度，可以随着时间的推移增加等待进程的优先级。

* 多级反馈队列
> * 一个进程需要执行 100 个时间片，如果采用时间片轮转调度算法，那么需要交换 100 次。
> * 多级队列是为这种需要连续执行多个时间片的进程考虑，它设置了多个队列，每个队列时间片大小都不同，例如 1,2,4,8,..。进程在第一个队列没执行完，就会被移到下一个队列。这种方式下，之前的进程只需要交换 7 次。
> * 每个队列优先权也不同，最上面的优先权最高。因此只有上一个队列没有进程在排队，才能调度当前队列上的进程。
> * 可以将这种调度算法看成是时间片轮转调度算法和优先级调度算法的结合。

### 实时系统
* 实时系统要求一个请求在一个确定时间内得到响应。
* 分为硬实时和软实时，前者必须满足绝对的截止时间，后者可以容忍一定的超时。

## 僵尸进程和孤儿进程
* 当父进程先结束，子进程此时就会变成孤儿进程，孤儿进程会自动向上被init进程收养，init进程完成对状态收集工作。而且这种过继的方式也是守护进程能够实现的因素。
* 如果子进程先结束，父进程并未调用wait或者waitpid获取进程状态信息，回收进程资源，那么子进程描述符就会一直保存在系统中，这种进程称为僵尸进程。
    * 僵尸进程是每个子进程退出时必然经历的过程
    * 僵尸进程的危害
        * 如果进程不调用wait / waitpid的话， 那么保留的那段信息就不会释放，其进程号就会一直被占用，但是系统所能使用的进程号是有限的，如果大量的产生僵死进程，将因为没有可用的进程号而导致系统不能产生新的进程。  
    * 如何消除僵尸进程
        * kill发送SIGTERM或者SIGKILL信号消灭产生僵尸进程的进程，它产生的僵死进程就变成了孤儿进程，这些孤儿进程会被init进程接管
        * 子进程退出时向父进程发送SIGCHILD信号，父进程处理SIGCHILD信号。在信号处理函数中调用wait进行处理僵尸进程。 

## 进程状态转移
* 就绪状态（ready）：等待被调度
* 运行状态（running）
* 阻塞状态（waiting）：等待资源
> * 就绪状态的进程通过调度算法从而获得 CPU  时间，转为运行状态；而运行状态的进程，在分配给它的 CPU 时间片用完之后就会转为就绪状态，等待下一次调度。
> * 阻塞状态是缺少需要的资源从而由运行状态转换而来，但是该资源不包括 CPU 时间，缺少 CPU 时间会从运行态转换为就绪态。


## 进程间共享和私有资源
* 私有：地址空间、堆、全局变量、栈、寄存器
* 共享：代码段，公共数据，进程目录，进程ID

## 线程
线程是CPU调度的基本单位

## [协程](https://blog.csdn.net/pinganting/article/details/53750142)
[协程学习笔记](https://blog.csdn.net/somezz/article/details/81265198)
### 协程概述
* 协程是轻量级线程，拥有自己的寄存器上下文和栈。协程调度切换时，将寄存器上下文和栈保存到其他地方，在切回来的时候，恢复先前保存的寄存器上下文和栈。
* 协程能保留上一次调用时的状态，即所有局部状态的一个特定组合，每次过程重入时，就相当于进入上一次调用的状态。

### 协程和线程的区别
* 协程最大的优势就是协程极高的执行效率。因为子程序切换不是线程切换，而是由程序自身控制，因此，没有线程切换的开销，和多线程比，线程数量越多，协程的性能优势就越明显。
* 不需要多线程的锁机制，因为只有一个线程，也不存在同时写变量冲突，在协程中控制共享资源不加锁，只需要判断状态就好了，所以执行效率比多线程高很多。 

### 应用场景

* I/O 密集型任务。

> * 这一点与多线程有些类似，但协程调用是在一个线程内进行的，是单线程，切换的开销小，因此效率上略高于多线程。
> * 当程序在执行 I/O 时操作时，CPU 是空闲的，此时可以充分利用 CPU 的时间片来处理其他任务。在单线程中，一个函数调用，一般是从函数的第一行代码开始执行，结束于 return 语句、异常或者函数执行（也可以认为是隐式地返回了 None ）。 
> * 有了协程，我们在函数的执行过程中，如果遇到了耗时的 I/O 操作，函数可以临时让出控制权，让 CPU 执行其他函数，等 I/O 操作执行完毕以后再收回控制权。

## 线程间同步及系统调用
### 信号量
信号量是一种特殊的变量，可用于线程同步。它只取自然数值，并且只支持两种操作：
> * P(SV):如果信号量SV大于0，将它减一；如果SV值为0，则挂起该线程。
> * V(SV)：如果有其他进程因为等待SV而挂起，则唤醒，然后将SV+1；否则直接将SV+1。

* 系统调用
    * sem_wait（sem_t *sem）：以原子操作的方式将信号量减1，如果信号量值为0，则sem_wait将被阻塞，直到这个信号量具有非0值。
    * sem_post（sem_t *sem)：以原子操作将信号量值+1。当信号量大于0时，其他正在调用sem_wait等待信号量的线程将被唤醒。


### 互斥量

互斥量又称互斥锁，主要用于线程互斥，不能保证按序访问，可以和条件锁一起实现同步。当进入临界区      时，需要获得互斥锁并且加锁；当离开临界区时，需要对互斥锁解锁，以唤醒其他等待该互斥锁的线程。

* 系统调用
    * pthread_mutex_init:初始化互斥锁
    * pthread_mutex_destroy：销毁互斥锁
    * pthread_mutex_lock：以原子操作的方式给一个互斥锁加锁，如果目标互斥锁已经被上锁，pthread_mutex_lock调用将阻塞，直到该互斥锁的占有者将其解锁。
    * pthread_mutex_unlock:以一个原子操作的方式给一个互斥锁解锁。


### 条件变量

条件变量，用于在线程之间同步共享数据的值。条件变量提供一种线程间通信机制：当某个共享数据达到某个值时，唤醒等待这个共享数据的一个/多个线程。即，当某个共享变量等于某个值时，调用 signal/broadcast。此时操作共享变量时需要加锁。

* 系统调用
    * pthread_cond_init:初始化条件变量
    * pthread_cond_destroy：销毁条件变量
    * pthread_cond_signal：唤醒一个等待目标条件变量的线程。哪个线程被唤醒取决于调度策略和优先级。
    * pthread_cond_wait：等待目标条件变量。需要一个加锁的互斥锁确保操作的原子性。该函数中在进入wait状态前首先进行解锁，然后接收到信号后会再加锁，保证该线程对共享资源正确访问。 

## [线程间共享和私有资源](https://www.cnblogs.com/Lxk0825/p/9559070.html)
* 私有：线程栈，寄存器，程序寄存器，线程ID，错误返回码，信号屏蔽字，调度优先级
* 共享：文件描述符表，堆，地址空间，全局变量，静态变量，进程代码段，进程的当前目录和进程用户ID与进程组ID

## 进程与线程的区别
> * 进程是cpu资源分配的最小单位，线程是cpu调度的最小单位。
> * 进程有独立的系统资源，而同一进程内的线程共享进程的大部分系统资源,包括堆、代码段、数据段，每个线程只拥有一些在运行中必不可少的私有属性，比如tcb,线程Id,栈、寄存器。
> * 一个进程崩溃，不会对其他进程产生影响；而一个线程崩溃，会让同一进程内的其他线程也死掉。
> * 进程在创建、切换和销毁时开销比较大，而线程比较小。进程创建的时候需要分配系统资源，而销毁的的时候需要释放系统资源。进程切换需要分两步：切换页目录、刷新TLB以使用新的地址空间；切换内核栈和硬件上下文（寄存器）；而同一进程的线程间逻辑地址空间是一样的，不需要切换页目录、刷新TLB。
> * 进程间通信比较复杂，而同一进程的线程由于共享代码段和数据段，所以通信比较容易。 

### 为什么有了进程还需要线程？
* 优点
    * 进程可以使多个程序能并发执行，以提高资源的利用率和系统的吞吐量.
* 缺点
    * 进程在同一时间只能干一件事
    * 进程在执行的过程中如果阻塞，整个进程就会挂起，即使进程中有些工作不依赖于等待的资源，仍然不会执行。

因此，操作系统引入了比进程粒度更小的线程，作为并发执行的基本单位，从而减少程序在并发执行时所付出的时空开销，提高并发性

## 用户态和内核态

> * 用户态和内核态是操作系统的两种运行级别，两者最大的区别就是特权级不同。
> * 用户态拥有最低的特权级，内核态拥有较高的特权级。
> * 运行在用户态的程序不能直接访问操作系统内核数据结构和程序

### 两种状态转换
* 系统调用
    * 用户进程主动要求切换到内核态的一种方式，用户进程通过系统调用申请操作系统提供的服务程序完成工作 
* 异常
    * 当CPU在执行运行在用户态的程序时，发现了某些事件不可知的异常，这是会触发由当前运行进程切换到处理此异常的内核相关程序中，也就到了内核态，比如缺页异常。 
* 外围设备中断
    * 当外围设备完成用户请求的操作之后，会向CPU发出相应的中断信号，这时CPU会暂停执行下一条将要执行的指令，转而去执行中断信号的处理程序 
    * 比如硬盘读写操作完成，系统会切换到硬盘读写的中断处理程序中执行后续操作等 

## 存储器层次结构
### 层次结构
本地磁盘 -> 主存(DRAM) -> L3高速缓存(SRAM) -> L2高速缓存(SRAM) -> L1高速缓存(SRAM) -> L0寄存器

### 缓存思想
> * 位于K层的更快更小的存储设备作为位于K+1层更大更慢的存储设备的缓存
> * K+1层的存储器被划分成连续的数据对象组块，称为块，数据总是以块大小为传送单元在K和K+1层之间来回复制

### 缓存命中
> * 当程序需要K+1层的某个数据对象d时，首先在当前存储在K层的块中查找d，若d刚好缓存在k层中，则称为缓存命中
> * 若缓存不命中，则需要将K+1层中包含对象d的块缓存到K层中，若K层中满了，则需要替换现存的一个块

## 什么是虚拟内存
为了让物理内存扩充成更大的逻辑内存，从而让程序获得更多的可用内存，防止不同进程同一时刻在物理内存中运行而对物理内存的争夺和践踏，采用了虚拟内存。

为了更好的管理内存，操作系统将内存抽象成地址空间。每个程序拥有自己的地址空间，这个地址空间被分割成多个块，每一块称为一页。这些页被映射到物理内存，但**不需要映射到连续的物理内存**，也**不需要所有页都必须在物理内存中**。当程序引用到不在物理内存中的页时，由硬件执行必要的映射，将缺失的部分装入物理内存并重新执行失败的指令。

虚拟内存允许程序不用将地址空间中的每一页都映射到物理内存，也就是说一个程序不需要全部调入内存就可以运行，这使得有限的内存运行大程序成为可能。

## 虚拟内存页表寻址
### 分页
虚拟内存分割成虚拟页，物理内存被分割成物理页，用来作为磁盘和主存的传输单元。
虚拟页分为三个不相交的子集
> * 未分配的，不占磁盘空间
> * 缓存的，当前已缓存在物理内存中的已分配页，在页表中标志位为1
> * 未缓存的，未缓存在物理内存中的已分配页，在页表中标志位为0

### 页表
内存管理单元（MMU，属于硬件）管理着地址空间和物理内存的转换，操作系统为每一个进程维护了一个从虚拟地址到物理地址的映射关系的数据结构，叫页表，存储着程序地址空间到物理内存空间的映射表。

页表存放在物理内存中，物理页存放在物理内存中，虚拟页存放在磁盘上

### 页表寻址
> * 一个虚拟地址分为两部分，一部分存储页面号，一部分存储偏移量
> * 页表分为序号、页基地址、标志位
> * 访问虚拟地址，先通过页表查询页面号，查看标志位确认虚拟地址是否在物理内存中有缓存，然后由逻辑地址的高位部分先找到逻辑地址对应的页基地址，再由页基地址偏移虚拟地址中的偏移量就得到最后的物理地址
> * 一般情况下，这个过程都可以由硬件完成，所以效率还是比较高的。页式内存管理的优点就是比较灵活，内存管理以较小的页为单位，方便内存换入换出和扩充地址空间。 

## 缺页中断
在请求分页系统中，可以通过查询页表中的状态位来确定所要访问的页面是否存在于内存中。每当所要访问的页面不在内存时(缓存不命中)，会产生一次缺页中断，此时操作系统会根据页表中的外存地址在外存中找到所缺的一页，将其调入内存。

缺页本身是一种中断，与一般的中断一样，需要经过4个处理步骤：
> * 保护CPU现场
> * 分析中断原因
> * 转入缺页中断处理程序进行处理
> * 恢复CPU现场，继续执行

但是缺页中断是由于所要访问的页面不存在于内存时，由硬件所产生的一种特殊的中断，因此，与一般的中断存在区别：
> * 在指令执行期间产生和处理缺页中断信号
> * 一条指令在执行期间，可能产生多次缺页中断
> * 缺页中断返回是，执行产生中断的一条指令，而一般的中断返回是，执行下一条指令。 

## 虚拟内存置换算法
当访问一个内存中不存在的页，并且内存已满，则需要从内存中调出一个页或将数据送至磁盘对换区，替换一个页，这种现象叫做缺页置换。

当前操作系统最常采用的缺页置换算法如下：
> * 先进先出(FIFO)算法：置换最先调入内存的页面，即置换在内存中驻留时间最久的页面。按照进入内存的先后次序排列成队列，从队尾进入，从队首删除。

> * 最近最少使用（LRU）算法: 置换最近一段时间以来最长时间未访问过的页面。根据程序局部性原理，刚被访问的页面，可能马上又要被访问；而较长时间内没有被访问的页面，可能最近不会被访问。

当前最常采用的就是LRU算法。 

## 说一下LINUX系统中的锁
互斥锁，读写锁，自旋锁
> * 互斥锁：mutex，用于保证在任何时刻，都只能有一个线程访问该对象。**当获取锁操作失败时，线程会进入睡眠**，等待锁释放时被唤醒

> * 读写锁：rwlock，分为读锁和写锁。处于读操作时，可以允许多个线程同时获得读操作。但是同一时刻只能有一个线程可以获得写锁。其它**获取写锁失败的线程都会进入睡眠状态**，直到写锁释放时被唤醒。 注意：写锁会阻塞其它读写锁。当有一个线程获得写锁在写时，读锁也不能被其它线程获取；写者优先于读者（一旦有写者，则后续读者必须等待，唤醒时优先考虑写者）。适用于读取数据的频率远远大于写数据的频率的场合。

> * 自旋锁：spinlock，在任何时刻同样只能有一个线程访问对象。但是**当获取锁操作失败时，不会进入睡眠，而是会在原地自旋**，循环检测锁的保持者是否释放，直到锁被释放。这样节省了线程从睡眠状态到被唤醒期间的消耗，在加锁时间短暂的环境下会极大的提高效率。但如果加锁时间过长，则会非常浪费CPU资源。 

## 自旋锁发生死锁

## 死锁产生的条件
多个并发进程因争夺系统资源而产生相互等待的现象。

* 互斥条件：进程对所分配到的资源不允许其他进程访问，若其他进程访问该资源，只能等待，直至占有该资源的进程使用完成后释放该资源；

* 请求和保持条件：进程获得一定的资源后，又对其他资源发出请求，但是该资源可能被其他进程占有，此时请求阻塞，但该进程不会释放自己已经占有的资源

* 不可剥夺条件：进程已获得的资源，在未完成使用之前，不可被剥夺，只能在使用后自己释放

* 环路等待条件：进程发生死锁后，必然存在一个进程-资源之间的环形链 ，环路中每个进程都在等待下一个进程所占有的资源

## 如何避免死锁
* **破坏请求和等待条件。** 所有的进程在开始运行之前，必须一次性地申请其在整个运行过程中所需要的全部资源
* **破坏不可抢占条件。** 当进程新的资源未得到满足时，释放已占有的资源
* **破坏环路等待条件。** 系统给每类资源赋予一个序号，每个进程按编号递增的请求资源，释放则相反

## 死锁检测和死锁恢复
* 死锁检测
    * 每种类型一个资源的死锁检测
    * 每种类型多个资源的死锁检测
* 死锁恢复
    * **抢占恢复。** 从一个或多个进程中抢占足够数量的资源分配给死锁进程，以解除死锁状态
    * **回滚恢复。** 周期性地检查进程的状态（包括请求的资源），将其写入一个文件，当发生死锁，回滚到之前的某个时间点
    * **杀死进程恢复。** 终止或撤销系统中的一个或多个死锁进程，直至打破死锁状态。

